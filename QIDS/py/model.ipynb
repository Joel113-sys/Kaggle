{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HKU QIDS 2023 Quantitative Investment Competition: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from qids_package.qids import *\n",
    "import warnings\n",
    "from submit import submit\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 257248\n",
    "stock_num = 54\n",
    "day_num_total = 1000\n",
    "day_num = 1000 - 2\n",
    "test_day_num = 700\n",
    "timeslot_num = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(train, valid, test=None):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train)\n",
    "    train = scaler.transform(train)\n",
    "    valid = scaler.transform(valid)\n",
    "    if test is not None:\n",
    "        test = scaler.transform(test)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_corr(df1, df2):\n",
    "    new_df = pd.concat([df1,df2],axis=1)\n",
    "    return new_df.corr().iloc[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, train, valid, test, train_y, valid_y, return_pred=True, version=2, return_auc=False, plot_auc=False):\n",
    "    model.fit(train, train_y)\n",
    "    if version == 2:\n",
    "        model_train_y = model.predict(train)\n",
    "        model_valid_y = model.predict(valid)\n",
    "        pred = model.predict(test)\n",
    "        acr_train = model.score(train, train_y)\n",
    "        acr_valid = model.score(valid, valid_y)\n",
    "        print(calc_corr(train_y, model_train_y))\n",
    "        print(calc_corr(valid_y, model_valid_y))\n",
    "        if return_pred:\n",
    "            return pred\n",
    "\n",
    "def evaluate2(model, train, test, train_y, real_y, return_pred=True, version=2, return_auc=False, plot_auc=False):\n",
    "    model.fit(train, train_y)\n",
    "    if version == 2:\n",
    "        model_train_y = model.predict(train)\n",
    "        pred = np.array(model.predict(test)).reshape(-1,1)\n",
    "        pred_temp = pred[:37692]\n",
    "        real_y = np.array(real_y).reshape(-1,1)\n",
    "        # print(real_y.shape)\n",
    "        # print(pred.shape)\n",
    "        # print(\"train_score\",calc_corr(train_y, model_train_y))\n",
    "        # print(\"prediction_score\",calc_corr(pred, real_y))\n",
    "        train_y = pd.DataFrame(train_y)\n",
    "        model_train_y = pd.DataFrame(model_train_y)\n",
    "        combined0 = pd.concat([train_y,model_train_y],axis = 1)\n",
    "        print(combined0.corr())\n",
    "        pred_temp = pd.DataFrame(pred_temp)\n",
    "        real_y = pd.DataFrame(real_y)\n",
    "        combined = pd.concat([pred_temp,real_y],axis = 1)\n",
    "        print(combined.corr())\n",
    "        if return_pred:\n",
    "            return pred\n",
    "def evaluate3(model, train, test, train_y, real_y, return_pred=True, version=2, return_auc=False, plot_auc=False):\n",
    "    model.fit(train, train_y)\n",
    "    if version == 2:\n",
    "        model_train_y = model.predict(train)\n",
    "        pred = np.array(model.predict(test)).reshape(-1,1)\n",
    "        pred_temp = pred[:37692]\n",
    "        real_y = np.array(real_y).reshape(-1,1)\n",
    "        # print(real_y.shape)\n",
    "        # print(pred.shape)\n",
    "        # print(\"train_score\",calc_corr(train_y, model_train_y))\n",
    "        # print(\"prediction_score\",calc_corr(pred, real_y))\n",
    "        train_y = pd.DataFrame(train_y)\n",
    "        model_train_y = pd.DataFrame(model_train_y)\n",
    "        combined0 = pd.concat([train_y,model_train_y],axis = 1)\n",
    "        # print(combined0.corr())\n",
    "        pred_temp = pd.DataFrame(pred_temp)\n",
    "        real_y = pd.DataFrame(real_y)\n",
    "        combined = pd.concat([pred_temp,real_y],axis = 1)\n",
    "        # print(combined.corr())\n",
    "        if return_pred:\n",
    "            return pred, combined.corr().iloc[1,0]\n",
    "        \n",
    "#train 54 models respectively\n",
    "# def evaluate4(model, train_lst, test_lst, train_y_lst, real_y_lst):\n",
    "#     fit_lst = []\n",
    "#     pred_lst = []\n",
    "#     for i in range(54):\n",
    "#         model_sample = copy.deepcopy(model)\n",
    "#         model_sample.fit(train_lst[i], train_y_lst[i])\n",
    "#         fit_lst.append(model_sample.predict(train_lst[i])) \n",
    "#         pred_lst.append(np.array(model_sample.predict(test_lst[i])).reshape(-1,1))\n",
    "#         # # pred_temp_sample = pred_sample #[:37692] #暂时先不管最后两天\n",
    "#         # train_y_sample = pd.DataFrame(train_y_sample)\n",
    "#         # model_train_y_sample = pd.DataFrame(model_train_y_sample)\n",
    "#         # # combined0 = pd.concat([train_y_sample,model_train_y_sample],axis = 1)\n",
    "#         # pred_temp_sample = pd.DataFrame(pred_temp_sample)\n",
    "#         # real_y_sample = pd.DataFrame(real_y_sample)\n",
    "#         # combined = pd.concat([pred_temp_sample,real_y_sample],axis = 1)\n",
    "#         # sample_lst.append(pred_sample)\n",
    "#     # combined1 = pd.concat(sample_lst, axis=1)\n",
    "#     combined2 = pd.concat(pred_lst, axis=1)\n",
    "#     # print(combined1.corr())\n",
    "#     return combined2\n",
    "\n",
    "\n",
    "def evaluate4(model, train, test, train_y, real_y, return_pred=True, version=2, return_auc=False, plot_auc=False):\n",
    "    model.fit(train, train_y)\n",
    "    if version == 2:\n",
    "        model_train_y = model.predict(train)\n",
    "        pred = np.array(model.predict(test)).reshape(-1,1)\n",
    "        pred_temp = pred[:37692]\n",
    "        real_y = np.array(real_y).reshape(-1,1)\n",
    "        # print(real_y.shape)\n",
    "        # print(pred.shape)\n",
    "        # print(\"train_score\",calc_corr(train_y, model_train_y))\n",
    "        # print(\"prediction_score\",calc_corr(pred, real_y))\n",
    "        train_y = pd.DataFrame(train_y)\n",
    "        model_train_y = pd.DataFrame(model_train_y)\n",
    "        combined0 = pd.concat([train_y,model_train_y],axis = 1)\n",
    "        # print(combined0.corr())\n",
    "        pred_temp = pd.DataFrame(pred_temp)\n",
    "        real_y = pd.DataFrame(real_y)\n",
    "        combined = pd.concat([pred_temp,real_y],axis = 1)\n",
    "        # print(combined.corr())\n",
    "        if return_pred:\n",
    "            return pred, combined.corr().iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = \"../data/\"\n",
    "\n",
    "train_path = write_path + \"train.csv\"\n",
    "test_path = write_path + \"test.csv\"\n",
    "# real_return_path = write_path + \"real_return.csv\"\n",
    "real_return_path = write_path + \"real_return_reorder.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "real_return = pd.read_csv(real_return_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([train,valid],axis=0)\n",
    "\n",
    "train_y = train[\"return\"]\n",
    "train = train.drop(columns=[\"return\", \"date_time\",'stock_id','day'])\n",
    "# train = train.iloc[:, [4,14,15,17,18]]\n",
    "# train = train.drop(columns=[\"return\", \"date_time\",'stock_id'])\n",
    "# train = train.iloc[:, [4,14,15,17,18,21,22,23,24,25]]\n",
    "\n",
    "# valid_y = valid[\"return\"]\n",
    "# valid = valid.drop(columns=[\"return\", \"date_time\"])\n",
    "\n",
    "test = test.drop(columns=[\"date_time\",'stock_id','day'])\n",
    "# test = test.iloc[:, [4,14,15,17,18]]\n",
    "# test = test.drop(columns=[\"date_time\",'stock_id'])\n",
    "# test = test.iloc[:, [4,14,15,17,18,21,22,23,24,25]]\n",
    "\n",
    "real_return = real_return.drop(columns=[\"date_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turnoverRatio</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>pe_ttm</th>\n",
       "      <th>pe</th>\n",
       "      <th>pb</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>open_mean</th>\n",
       "      <th>close_mean</th>\n",
       "      <th>high_mean</th>\n",
       "      <th>low_mean</th>\n",
       "      <th>volume_mean</th>\n",
       "      <th>money_mean</th>\n",
       "      <th>high_max</th>\n",
       "      <th>volume_max</th>\n",
       "      <th>money_max</th>\n",
       "      <th>low_min</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>price_diff_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.6794</td>\n",
       "      <td>17229.0</td>\n",
       "      <td>34.4425</td>\n",
       "      <td>32.3029</td>\n",
       "      <td>4.9425</td>\n",
       "      <td>3.8180</td>\n",
       "      <td>-578.7700</td>\n",
       "      <td>24.550554</td>\n",
       "      <td>24.536720</td>\n",
       "      <td>24.578718</td>\n",
       "      <td>24.508076</td>\n",
       "      <td>454075.84</td>\n",
       "      <td>1.114925e+07</td>\n",
       "      <td>25.1378</td>\n",
       "      <td>1234546.0</td>\n",
       "      <td>3.056567e+07</td>\n",
       "      <td>24.2396</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>0.007816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.2535</td>\n",
       "      <td>18378.0</td>\n",
       "      <td>33.3198</td>\n",
       "      <td>31.2498</td>\n",
       "      <td>4.7814</td>\n",
       "      <td>3.6935</td>\n",
       "      <td>-559.9031</td>\n",
       "      <td>23.955800</td>\n",
       "      <td>23.938318</td>\n",
       "      <td>23.988574</td>\n",
       "      <td>23.907490</td>\n",
       "      <td>401517.02</td>\n",
       "      <td>9.601600e+06</td>\n",
       "      <td>24.5552</td>\n",
       "      <td>853209.0</td>\n",
       "      <td>2.052481e+07</td>\n",
       "      <td>23.5234</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.010720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.4947</td>\n",
       "      <td>13686.0</td>\n",
       "      <td>23.3887</td>\n",
       "      <td>23.3887</td>\n",
       "      <td>4.3823</td>\n",
       "      <td>2.9722</td>\n",
       "      <td>-42.8676</td>\n",
       "      <td>23.626130</td>\n",
       "      <td>23.628554</td>\n",
       "      <td>23.661090</td>\n",
       "      <td>23.591664</td>\n",
       "      <td>307969.24</td>\n",
       "      <td>7.275962e+06</td>\n",
       "      <td>23.7783</td>\n",
       "      <td>708274.0</td>\n",
       "      <td>1.677659e+07</td>\n",
       "      <td>23.3899</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.007741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.5625</td>\n",
       "      <td>22587.0</td>\n",
       "      <td>23.9187</td>\n",
       "      <td>23.9187</td>\n",
       "      <td>4.4816</td>\n",
       "      <td>3.0396</td>\n",
       "      <td>-43.8390</td>\n",
       "      <td>23.837576</td>\n",
       "      <td>23.847280</td>\n",
       "      <td>23.879820</td>\n",
       "      <td>23.803594</td>\n",
       "      <td>563240.50</td>\n",
       "      <td>1.344701e+07</td>\n",
       "      <td>24.3610</td>\n",
       "      <td>1503134.0</td>\n",
       "      <td>3.517868e+07</td>\n",
       "      <td>23.3778</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.009644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.2257</td>\n",
       "      <td>65239.0</td>\n",
       "      <td>25.9119</td>\n",
       "      <td>25.9119</td>\n",
       "      <td>4.8551</td>\n",
       "      <td>3.2929</td>\n",
       "      <td>-47.4923</td>\n",
       "      <td>25.965612</td>\n",
       "      <td>26.002992</td>\n",
       "      <td>26.075094</td>\n",
       "      <td>25.890594</td>\n",
       "      <td>2249971.94</td>\n",
       "      <td>5.879807e+07</td>\n",
       "      <td>26.7036</td>\n",
       "      <td>15974670.0</td>\n",
       "      <td>4.255601e+08</td>\n",
       "      <td>23.9847</td>\n",
       "      <td>0.039728</td>\n",
       "      <td>0.039728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53887</th>\n",
       "      <td>0.6555</td>\n",
       "      <td>5554.0</td>\n",
       "      <td>9.9428</td>\n",
       "      <td>9.9428</td>\n",
       "      <td>1.8629</td>\n",
       "      <td>0.3802</td>\n",
       "      <td>125.5971</td>\n",
       "      <td>9.333880</td>\n",
       "      <td>9.334846</td>\n",
       "      <td>9.353058</td>\n",
       "      <td>9.316162</td>\n",
       "      <td>128145.22</td>\n",
       "      <td>1.195648e+06</td>\n",
       "      <td>9.4676</td>\n",
       "      <td>387389.0</td>\n",
       "      <td>3.608737e+06</td>\n",
       "      <td>9.2127</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.011791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53888</th>\n",
       "      <td>0.6154</td>\n",
       "      <td>6417.0</td>\n",
       "      <td>10.0148</td>\n",
       "      <td>10.0148</td>\n",
       "      <td>1.8764</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>126.5072</td>\n",
       "      <td>9.349170</td>\n",
       "      <td>9.349170</td>\n",
       "      <td>9.359846</td>\n",
       "      <td>9.332672</td>\n",
       "      <td>120310.78</td>\n",
       "      <td>1.124447e+06</td>\n",
       "      <td>9.3827</td>\n",
       "      <td>283148.0</td>\n",
       "      <td>2.642756e+06</td>\n",
       "      <td>9.2492</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.010389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53889</th>\n",
       "      <td>0.8417</td>\n",
       "      <td>5204.0</td>\n",
       "      <td>10.1469</td>\n",
       "      <td>10.1469</td>\n",
       "      <td>1.9012</td>\n",
       "      <td>0.3880</td>\n",
       "      <td>128.1758</td>\n",
       "      <td>9.436804</td>\n",
       "      <td>9.440208</td>\n",
       "      <td>9.455750</td>\n",
       "      <td>9.424180</td>\n",
       "      <td>164545.76</td>\n",
       "      <td>1.554019e+06</td>\n",
       "      <td>9.5162</td>\n",
       "      <td>615056.0</td>\n",
       "      <td>5.839099e+06</td>\n",
       "      <td>9.2613</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.013057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53890</th>\n",
       "      <td>1.4411</td>\n",
       "      <td>9143.0</td>\n",
       "      <td>10.4471</td>\n",
       "      <td>10.4471</td>\n",
       "      <td>1.9574</td>\n",
       "      <td>0.3995</td>\n",
       "      <td>131.9680</td>\n",
       "      <td>9.811140</td>\n",
       "      <td>9.816240</td>\n",
       "      <td>9.844646</td>\n",
       "      <td>9.790510</td>\n",
       "      <td>281720.62</td>\n",
       "      <td>2.775468e+06</td>\n",
       "      <td>10.1838</td>\n",
       "      <td>2456106.0</td>\n",
       "      <td>2.435143e+07</td>\n",
       "      <td>9.5041</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>0.032380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53891</th>\n",
       "      <td>1.2933</td>\n",
       "      <td>9681.0</td>\n",
       "      <td>10.6513</td>\n",
       "      <td>10.6513</td>\n",
       "      <td>1.9956</td>\n",
       "      <td>0.4073</td>\n",
       "      <td>134.5467</td>\n",
       "      <td>9.820860</td>\n",
       "      <td>9.827900</td>\n",
       "      <td>9.850964</td>\n",
       "      <td>9.793908</td>\n",
       "      <td>252827.46</td>\n",
       "      <td>2.483025e+06</td>\n",
       "      <td>9.9896</td>\n",
       "      <td>894193.0</td>\n",
       "      <td>8.680005e+06</td>\n",
       "      <td>9.6012</td>\n",
       "      <td>0.014920</td>\n",
       "      <td>0.017410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53892 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       turnoverRatio  transactionAmount   pe_ttm       pe      pb      ps  \\\n",
       "0             3.6794            17229.0  34.4425  32.3029  4.9425  3.8180   \n",
       "1             3.2535            18378.0  33.3198  31.2498  4.7814  3.6935   \n",
       "2             2.4947            13686.0  23.3887  23.3887  4.3823  2.9722   \n",
       "3             4.5625            22587.0  23.9187  23.9187  4.4816  3.0396   \n",
       "4            18.2257            65239.0  25.9119  25.9119  4.8551  3.2929   \n",
       "...              ...                ...      ...      ...     ...     ...   \n",
       "53887         0.6555             5554.0   9.9428   9.9428  1.8629  0.3802   \n",
       "53888         0.6154             6417.0  10.0148  10.0148  1.8764  0.3830   \n",
       "53889         0.8417             5204.0  10.1469  10.1469  1.9012  0.3880   \n",
       "53890         1.4411             9143.0  10.4471  10.4471  1.9574  0.3995   \n",
       "53891         1.2933             9681.0  10.6513  10.6513  1.9956  0.4073   \n",
       "\n",
       "            pcf  open_mean  close_mean  high_mean   low_mean  volume_mean  \\\n",
       "0     -578.7700  24.550554   24.536720  24.578718  24.508076    454075.84   \n",
       "1     -559.9031  23.955800   23.938318  23.988574  23.907490    401517.02   \n",
       "2      -42.8676  23.626130   23.628554  23.661090  23.591664    307969.24   \n",
       "3      -43.8390  23.837576   23.847280  23.879820  23.803594    563240.50   \n",
       "4      -47.4923  25.965612   26.002992  26.075094  25.890594   2249971.94   \n",
       "...         ...        ...         ...        ...        ...          ...   \n",
       "53887  125.5971   9.333880    9.334846   9.353058   9.316162    128145.22   \n",
       "53888  126.5072   9.349170    9.349170   9.359846   9.332672    120310.78   \n",
       "53889  128.1758   9.436804    9.440208   9.455750   9.424180    164545.76   \n",
       "53890  131.9680   9.811140    9.816240   9.844646   9.790510    281720.62   \n",
       "53891  134.5467   9.820860    9.827900   9.850964   9.793908    252827.46   \n",
       "\n",
       "         money_mean  high_max  volume_max     money_max  low_min  price_diff  \\\n",
       "0      1.114925e+07   25.1378   1234546.0  3.056567e+07  24.2396    0.006510   \n",
       "1      9.601600e+06   24.5552    853209.0  2.052481e+07  23.5234    0.004981   \n",
       "2      7.275962e+06   23.7783    708274.0  1.677659e+07  23.3899    0.007227   \n",
       "3      1.344701e+07   24.3610   1503134.0  3.517868e+07  23.3778    0.009134   \n",
       "4      5.879807e+07   26.7036  15974670.0  4.255601e+08  23.9847    0.039728   \n",
       "...             ...       ...         ...           ...      ...         ...   \n",
       "53887  1.195648e+06    9.4676    387389.0  3.608737e+06   9.2127    0.007871   \n",
       "53888  1.124447e+06    9.3827    283148.0  2.642756e+06   9.2492    0.005203   \n",
       "53889  1.554019e+06    9.5162    615056.0  5.839099e+06   9.2613    0.006528   \n",
       "53890  2.775468e+06   10.1838   2456106.0  2.435143e+07   9.5041    0.021176   \n",
       "53891  2.483025e+06    9.9896    894193.0  8.680005e+06   9.6012    0.014920   \n",
       "\n",
       "       price_diff_max  \n",
       "0            0.007816  \n",
       "1            0.010720  \n",
       "2            0.007741  \n",
       "3            0.009644  \n",
       "4            0.039728  \n",
       "...               ...  \n",
       "53887        0.011791  \n",
       "53888        0.010389  \n",
       "53889        0.013057  \n",
       "53890        0.032380  \n",
       "53891        0.017410  \n",
       "\n",
       "[53892 rows x 19 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featureing engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def growth(data, features, group):\n",
    "    \n",
    "    \"\"\"\n",
    "    create growth rate column based on selected features\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for feature in features:\n",
    "        data[f'{feature}_growth'] = grouped[feature].pct_change()\n",
    "    return data\n",
    "\n",
    "def lag_feature_with_group(data, features, n, group):\n",
    "    \n",
    "    \"\"\"\n",
    "    create a lagged column in data from feature with n lagging periods\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for feature in features:\n",
    "            data[f'{feature}_{i}'] = grouped[feature].shift(i)\n",
    "    return data\n",
    "\n",
    "def sma(data, features, n, group):\n",
    "    \n",
    "    \"\"\"\n",
    "    create sma(n) column in data from feature\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for i in n:\n",
    "        for feature in features:\n",
    "            data[f'{feature}_sma{i}'] = grouped.rolling(i)[feature].mean().reset_index(drop=True)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'code'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m features \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mpe_ttm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpe\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mps\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpcf\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sma_periods \u001b[39m=\u001b[39m [\u001b[39m10\u001b[39m,\u001b[39m25\u001b[39m,\u001b[39m50\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_lag \u001b[39m=\u001b[39m lag_feature_with_group(train, features, \u001b[39m2\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcode\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df_sma \u001b[39m=\u001b[39m sma(df_lag, features, sma_periods, \u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_growth \u001b[39m=\u001b[39m growth(df_sma, features, \u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb Cell 15\u001b[0m in \u001b[0;36mlag_feature_with_group\u001b[0;34m(data, features, n, group)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlag_feature_with_group\u001b[39m(data, features, n, group):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m    create a lagged column in data from feature with n lagging periods\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     grouped \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mgroupby(group)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/model.ipynb#X66sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:7712\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   7707\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m   7709\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[1;32m   7710\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[1;32m   7711\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[0;32m-> 7712\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   7713\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   7714\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   7715\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   7716\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   7717\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   7718\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   7719\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   7720\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   7721\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   7722\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   7723\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    883\u001b[0m         obj,\n\u001b[1;32m    884\u001b[0m         keys,\n\u001b[1;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[1;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[1;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    880\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'code'"
     ]
    }
   ],
   "source": [
    "features = ['pe_ttm', 'pe', 'pb', 'ps', 'pcf']\n",
    "sma_periods = [10,25,50]\n",
    "df_lag = lag_feature_with_group(train, features, 2, 'code')\n",
    "df_sma = sma(df_lag, features, sma_periods, 'code')\n",
    "df_growth = growth(df_sma, features, 'code')\n",
    "fig, ax = plt.subplots(figsize=(7,15))\n",
    "sns.heatmap(df_lag.corr(numeric_only=True)[['return']].sort_values(by='return', ascending=False),annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lst = []\n",
    "train_y_lst = []\n",
    "test_lst = []\n",
    "real_y_lst = []\n",
    "for i in range(54):\n",
    "    idx1 = 998 * i \n",
    "    idx2 = 998 * (i + 1)\n",
    "    test_idx1 = 700 * i\n",
    "    test_idx2 = 700 * (i+1)\n",
    "    return_idx1 = 698 * i\n",
    "    return_idx2 = 698 * (i + 1)\n",
    "    train_lst.append(train.iloc[idx1:idx2])\n",
    "    train_y_lst.append(train_y.iloc[idx1:idx2].reset_index()[\"return\"])\n",
    "    test_lst.append(test.iloc[test_idx1:test_idx2])\n",
    "    real_y_lst.append(real_return.iloc[return_idx1:return_idx2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.002691\n",
       "1      0.030722\n",
       "2      0.043125\n",
       "3      0.032530\n",
       "4     -0.028420\n",
       "         ...   \n",
       "993   -0.006676\n",
       "994   -0.030473\n",
       "995   -0.012935\n",
       "996   -0.003142\n",
       "997   -0.006291\n",
       "Name: return, Length: 998, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_lst[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respective training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03739290549236048\n",
      "0.0528763314307535\n",
      "0.08440199524459187\n",
      "0.08506211682573905\n",
      "0.10194030580598051\n",
      "-0.11472481231613317\n",
      "0.06253255197121713\n",
      "0.020348301414995915\n",
      "0.060636984865386136\n",
      "0.10536644404748478\n",
      "0.02496330615221728\n",
      "0.09367685634466384\n",
      "0.08373573068663256\n",
      "0.06770084633799428\n",
      "0.004879001325647432\n",
      "0.10391302220943721\n",
      "0.07332708970225943\n",
      "0.18683368559462932\n",
      "0.09509856140201435\n",
      "0.002136451321401611\n",
      "0.046881507373763336\n",
      "0.06249442911882179\n",
      "0.06777729914104666\n",
      "0.09373066077697496\n",
      "0.047075011659767484\n",
      "-0.04812061745481187\n",
      "0.016734047025425643\n",
      "0.05420140224237148\n",
      "-0.008308043358806224\n",
      "0.005103415619597138\n",
      "0.07453693972100134\n",
      "0.11310301784501647\n",
      "0.07150016174106859\n",
      "0.012182148355326782\n",
      "0.14449562920682388\n",
      "0.07969499227647163\n",
      "0.01618678989779944\n",
      "0.09421112149313503\n",
      "0.0069810241602210775\n",
      "0.08237443657640027\n",
      "0.08152853752701118\n",
      "0.12831501708794002\n",
      "0.015653225607087522\n",
      "0.008215121233348716\n",
      "0.06874070685014995\n",
      "-0.027205633661747386\n",
      "0.08196945467366963\n",
      "0.11810013015834298\n",
      "-0.020870285419956742\n",
      "0.048755328667472606\n",
      "0.08603222148768377\n",
      "0.03291629354965398\n",
      "0.10104294847227403\n",
      "0.0022909934210436594\n"
     ]
    }
   ],
   "source": [
    "for i in range(54):\n",
    "    model = make_pipeline(StandardScaler(),SGDRegressor(max_iter=10000, tol=1e-6,penalty='l1',random_state=1))\n",
    "    pred_temp,score = evaluate2(model, train_lst[i], test_lst[i], train_y_lst[i], real_y_lst[i])\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest score -0.016799805761044014\n",
      "it is the 0 -th model now\n",
      "highest score 0.05537885154256209\n",
      "it is the 1 -th model now\n",
      "highest score 0.1007737951360895\n",
      "it is the 2 -th model now\n",
      "highest score 0.1542549749315663\n",
      "it is the 3 -th model now\n",
      "highest score 0.11542623825546379\n",
      "it is the 4 -th model now\n",
      "highest score -0.02990700219809435\n",
      "it is the 5 -th model now\n",
      "highest score 0.08497795185735825\n",
      "it is the 6 -th model now\n",
      "highest score 0.08700370780222226\n",
      "it is the 7 -th model now\n",
      "highest score 0.06669985576343174\n",
      "it is the 8 -th model now\n",
      "highest score 0.12666961040032754\n",
      "it is the 9 -th model now\n",
      "highest score 0.03385930104822651\n",
      "it is the 10 -th model now\n",
      "highest score 0.10709476442878112\n",
      "it is the 11 -th model now\n",
      "highest score 0.10230885158682576\n",
      "it is the 12 -th model now\n",
      "highest score 0.0852983679160526\n",
      "it is the 13 -th model now\n",
      "highest score 0.019089321572681412\n",
      "it is the 14 -th model now\n",
      "highest score 0.11799042954283637\n",
      "it is the 15 -th model now\n",
      "highest score 0.11066077264163462\n",
      "it is the 16 -th model now\n",
      "highest score 0.19816162646903515\n",
      "it is the 17 -th model now\n",
      "highest score 0.14954898688305918\n",
      "it is the 18 -th model now\n",
      "highest score 0.019567258609819928\n",
      "it is the 19 -th model now\n",
      "highest score 0.07389274209812315\n",
      "it is the 20 -th model now\n",
      "highest score 0.08771536940284536\n",
      "it is the 21 -th model now\n",
      "highest score 0.08177517176633976\n",
      "it is the 22 -th model now\n",
      "highest score 0.11556943221337933\n",
      "it is the 23 -th model now\n",
      "highest score 0.053749070840109\n",
      "it is the 24 -th model now\n",
      "highest score -0.038838979776618154\n",
      "it is the 25 -th model now\n",
      "highest score 0.01902313381364426\n",
      "it is the 26 -th model now\n",
      "highest score 0.05668954080220982\n",
      "it is the 27 -th model now\n",
      "highest score 0.12054631242177902\n",
      "it is the 28 -th model now\n",
      "highest score 0.008447067906470582\n",
      "it is the 29 -th model now\n",
      "highest score 0.10554169136596138\n",
      "it is the 30 -th model now\n",
      "highest score 0.148655983539651\n",
      "it is the 31 -th model now\n",
      "highest score 0.13776243266666371\n",
      "it is the 32 -th model now\n",
      "highest score 0.05687381906993446\n",
      "it is the 33 -th model now\n",
      "highest score 0.15318749686745803\n",
      "it is the 34 -th model now\n",
      "highest score 0.08220999512608991\n",
      "it is the 35 -th model now\n",
      "highest score 0.07731066095365588\n",
      "it is the 36 -th model now\n",
      "highest score 0.1012152596331426\n",
      "it is the 37 -th model now\n",
      "highest score 0.03206505628924831\n",
      "it is the 38 -th model now\n",
      "highest score 0.13572547828017523\n",
      "it is the 39 -th model now\n",
      "highest score 0.09400696861558419\n",
      "it is the 40 -th model now\n",
      "highest score 0.15850224766188517\n",
      "it is the 41 -th model now\n",
      "highest score 0.0716886781711862\n",
      "it is the 42 -th model now\n",
      "highest score 0.04722391931543347\n",
      "it is the 43 -th model now\n",
      "highest score 0.0733969628341046\n",
      "it is the 44 -th model now\n",
      "highest score -0.023069677395387175\n",
      "it is the 45 -th model now\n",
      "highest score 0.0941272432885543\n",
      "it is the 46 -th model now\n",
      "highest score 0.18040796510580753\n",
      "it is the 47 -th model now\n",
      "highest score -0.016310165151354434\n",
      "it is the 48 -th model now\n",
      "highest score 0.05721087464612622\n",
      "it is the 49 -th model now\n",
      "highest score 0.0897408093613723\n",
      "it is the 50 -th model now\n",
      "highest score 0.038371654487223066\n",
      "it is the 51 -th model now\n",
      "highest score 0.10375783237189115\n",
      "it is the 52 -th model now\n",
      "highest score 0.03237013390790638\n",
      "it is the 53 -th model now\n",
      "correlation is: 0.006733758185776247\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# model = LinearRegression()\n",
    "model_lst = []\n",
    "count_score = 0\n",
    "for i in range(1000):\n",
    "    model_lst.append(make_pipeline(StandardScaler(),SGDRegressor(max_iter=10000, tol=1e-6,penalty='l1',random_state=i)))\n",
    "    # model_lst.append(linear_model.Lasso(alpha=i))\n",
    "    # model_lst.append(LinearRegression())\n",
    "pred_lst = []\n",
    "for i in range(54):\n",
    " \n",
    "    score_lst = []\n",
    "    temp_score_lst = []\n",
    "    idx_lst = []\n",
    "    for j in range(1000):\n",
    "        model = model_lst[j]\n",
    "        pred_temp, score = evaluate4(model, train_lst[i], test_lst[i], train_y_lst[i], real_y_lst[i])\n",
    "        temp_score_lst.append(score)\n",
    "        # print(temp_score_lst)\n",
    "    max_idx = temp_score_lst.index(max(temp_score_lst))\n",
    "    # print(\"maxindex\",max_idx)\n",
    "    pred_store,score = evaluate4(model_lst[max_idx], train_lst[i], test_lst[i], train_y_lst[i], real_y_lst[i])\n",
    "    print('highest score',score)\n",
    "    count_score += score\n",
    "    pred_lst.append(pd.DataFrame(pred_store))\n",
    "    # print(pred_lst)\n",
    "    print(\"it is the\",i,'-th model now')\n",
    "# print(pred_lst)\n",
    "pred_com = pd.concat(pred_lst,axis = 0)\n",
    "pred_com = pred_com.reset_index()\n",
    "# print(pred_com)\n",
    "combined = pd.concat([pred_com[:37692],real_return],axis = 1)\n",
    "print(\"correlation is:\", combined.corr().iloc[1,2])\n",
    "score_lst.append(combined.corr().iloc[1,2])\n",
    "\n",
    "# print(max(score_lst), score_lst.index(max(score_lst)))\n",
    "# print(count_score/54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.215917</td>\n",
       "      <td>0.023414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.215917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>0.023414</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index         0    return\n",
       "index   1.000000 -0.215917  0.023414\n",
       "0      -0.215917  1.000000  0.006734\n",
       "return  0.023414  0.006734  1.000000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_com = pred_com.drop('index',axis = 1)\n",
    "# pd.concat([pred_com[:37692],real_return],axis = 1).corr()\n",
    "# calc_corr(pred_com, real_return)\n",
    "pd.concat([pred_com, real_return], axis = 1).corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          return         0\n",
      "return  1.000000  0.062593\n",
      "0       0.062593  1.000000\n",
      "          0         0\n",
      "0  1.000000 -0.012425\n",
      "0 -0.012425  1.000000\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "pred = evaluate2(model, train, test, train_y, real_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37795</th>\n",
       "      <td>-0.001919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37796</th>\n",
       "      <td>-0.004109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37797</th>\n",
       "      <td>-0.005192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37798</th>\n",
       "      <td>-0.002927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37799</th>\n",
       "      <td>-0.001874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37800 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      0.000878\n",
       "1      0.001435\n",
       "2      0.001100\n",
       "3      0.000901\n",
       "4      0.000411\n",
       "...         ...\n",
       "37795 -0.001919\n",
       "37796 -0.004109\n",
       "37797 -0.005192\n",
       "37798 -0.002927\n",
       "37799 -0.001874\n",
       "\n",
       "[37800 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 10\n",
      "          return         0\n",
      "return  1.000000  0.080408\n",
      "0       0.080408  1.000000\n",
      "          0         0\n",
      "0  1.000000 -0.006913\n",
      "0 -0.006913  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "for i in range(10):\n",
    "    reg = Ridge(alpha=i)\n",
    "    print(\"i =\",i)\n",
    "    pred = evaluate2(reg, train, test, train_y, real_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.44740422e-06, -4.37143067e-07,  5.89291065e-09,  4.55263535e-11,\n",
       "       -3.04095352e-10,  2.56186426e-11])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 7\n",
      "         return        0\n",
      "return  1.00000  0.05818\n",
      "0       0.05818  1.00000\n",
      "          0         0\n",
      "0  1.000000 -0.011034\n",
      "0 -0.011034  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "for i in [7]:\n",
    "    print(\"i =\",i)\n",
    "    reg = linear_model.Lasso(alpha=i)\n",
    "    pred = evaluate2(reg, train, test, train_y, real_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00000000e+00, -2.27469085e-07, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -2.99777096e-10,\n",
       "        1.75605909e-10,  0.00000000e+00, -1.79070137e-09,  3.12846753e-11,\n",
       "        0.00000000e+00, -0.00000000e+00, -5.36817865e-10,  1.47841542e-08,\n",
       "       -2.15848399e-10, -3.22466059e-16,  1.81756503e-19, -0.00000000e+00,\n",
       "       -0.00000000e+00])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          return         0\n",
      "return  1.000000  0.031914\n",
      "0       0.031914  1.000000\n",
      "         0        0\n",
      "0  1.00000 -0.00211\n",
      "0 -0.00211  1.00000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "regr = make_pipeline(StandardScaler(),LinearSVR(random_state=0, tol=1e-5))\n",
    "pred = evaluate2(regr, train, test, train_y, real_return)\n",
    "# evaluate2(model, train, test, train_y,test_y ,return_pred=True, version=2, return_auc=False, plot_auc=False):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          return         0\n",
      "return  1.000000  0.145667\n",
      "0       0.145667  1.000000\n",
      "          0         0\n",
      "0  1.000000 -0.002612\n",
      "0 -0.002612  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.1))\n",
    "pred = evaluate2(regr, train, test, train_y, real_return)\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define the pipeline\n",
    "# regr = make_pipeline(StandardScaler(), SVR())\n",
    "\n",
    "# # Define the hyperparameters to search over\n",
    "# param_grid = {\n",
    "#     'svr__C': [0.1, 1, 10],\n",
    "#     'svr__gamma': [0.1, 1, 10],\n",
    "#     'svr__epsilon': [0.1, 0.01, 0.001],\n",
    "# }\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# grid_search = GridSearchCV(regr, param_grid, cv=5, n_jobs=-1)\n",
    "# grid_search.fit(train, train_y)\n",
    "\n",
    "# # Print the best hyperparameters and test score\n",
    "# print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "# print(\"Test score: \", grid_search.score(test, real_return))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          return         0\n",
      "return  1.000000  0.170887\n",
      "0       0.170887  1.000000\n",
      "          0         0\n",
      "0  1.000000  0.015523\n",
      "0  0.015523  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, ensemble\n",
    "\n",
    "for l in [0.99]:\n",
    "    params = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": 3,\n",
    "        \"min_samples_split\": 8,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"loss\": \"huber\",\n",
    "        \"alpha\": l,\n",
    "    }\n",
    "\n",
    "    reg = ensemble.GradientBoostingRegressor(**params)\n",
    "    pred = evaluate2(reg, train, test, train_y, real_return)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.061560105033462806\n",
      "0.061560105033462806\n",
      "0.061560105033462806\n",
      "0.06807174173976324\n",
      "0.06807174173976324\n",
      "0.06807174173976324\n",
      "0.06199096481704358\n",
      "0.06199096481704358\n",
      "0.06199096481704358\n",
      "0.05999080175204827\n",
      "0.05999080175204827\n",
      "0.05999080175204827\n",
      "0.06292973318709269\n",
      "0.06292973318709269\n",
      "0.06292973318709269\n",
      "0.050925137454654934\n",
      "0.050925137454654934\n",
      "0.050925137454654934\n",
      "0.04871031743847376\n",
      "0.04871031743847376\n",
      "0.04871031743847376\n",
      "0.06362077173358995\n",
      "0.06362077173358995\n",
      "0.06362077173358995\n",
      "0.05045546512997368\n",
      "0.05045546512997368\n",
      "0.05045546512997368\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/joellau/Desktop/qids/py/model.ipynb Cell 38\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joellau/Desktop/qids/py/model.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m reg \u001b[39m=\u001b[39m make_pipeline(StandardScaler(),SGDRegressor(max_iter\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, tol\u001b[39m=\u001b[39m\u001b[39m1e-6\u001b[39m,penalty\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ml1\u001b[39m\u001b[39m'\u001b[39m,random_state\u001b[39m=\u001b[39mi))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joellau/Desktop/qids/py/model.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# pred = evaluate2(reg, train, test, train_y, real_return)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/joellau/Desktop/qids/py/model.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pred, score \u001b[39m=\u001b[39m evaluate3(reg, train, test, train_y, real_return)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/qids/py/model.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(score)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/qids/py/model.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m score_lst\u001b[39m.\u001b[39mappend(score)\n",
      "\u001b[1;32m/Users/joellau/Desktop/qids/py/model.ipynb Cell 38\u001b[0m in \u001b[0;36mevaluate3\u001b[0;34m(model, train, test, train_y, real_y, return_pred, version, return_auc, plot_auc)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/qids/py/model.ipynb#X43sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate3\u001b[39m(model, train, test, train_y, real_y, return_pred\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, version\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, return_auc\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, plot_auc\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/joellau/Desktop/qids/py/model.ipynb#X43sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(train, train_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/qids/py/model.ipynb#X43sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mif\u001b[39;00m version \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/qids/py/model.ipynb#X43sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         model_train_y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(train)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    393\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 394\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1537\u001b[0m, in \u001b[0;36mBaseSGDRegressor.fit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, coef_init\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, intercept_init\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1513\u001b[0m     \u001b[39m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m \n\u001b[1;32m   1515\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[39m        Fitted `SGDRegressor` estimator.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1537\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m   1538\u001b[0m         X,\n\u001b[1;32m   1539\u001b[0m         y,\n\u001b[1;32m   1540\u001b[0m         alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[1;32m   1541\u001b[0m         C\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m   1542\u001b[0m         loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[1;32m   1543\u001b[0m         learning_rate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[1;32m   1544\u001b[0m         coef_init\u001b[39m=\u001b[39;49mcoef_init,\n\u001b[1;32m   1545\u001b[0m         intercept_init\u001b[39m=\u001b[39;49mintercept_init,\n\u001b[1;32m   1546\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1547\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1485\u001b[0m, in \u001b[0;36mBaseSGDRegressor._fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[39m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_ \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m-> 1485\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[1;32m   1486\u001b[0m     X,\n\u001b[1;32m   1487\u001b[0m     y,\n\u001b[1;32m   1488\u001b[0m     alpha,\n\u001b[1;32m   1489\u001b[0m     C,\n\u001b[1;32m   1490\u001b[0m     loss,\n\u001b[1;32m   1491\u001b[0m     learning_rate,\n\u001b[1;32m   1492\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1493\u001b[0m     sample_weight,\n\u001b[1;32m   1494\u001b[0m     coef_init,\n\u001b[1;32m   1495\u001b[0m     intercept_init,\n\u001b[1;32m   1496\u001b[0m )\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39m>\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf\n\u001b[1;32m   1501\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter\n\u001b[1;32m   1502\u001b[0m ):\n\u001b[1;32m   1503\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMaximum number of iteration reached before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1505\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconvergence. Consider increasing max_iter to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1506\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mimprove the fit.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1507\u001b[0m         ConvergenceWarning,\n\u001b[1;32m   1508\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1415\u001b[0m, in \u001b[0;36mBaseSGDRegressor._partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m   1412\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_average_coef \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(n_features, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1413\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_average_intercept \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1415\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_regressor(\n\u001b[1;32m   1416\u001b[0m     X, y, alpha, C, loss, learning_rate, sample_weight, max_iter\n\u001b[1;32m   1417\u001b[0m )\n\u001b[1;32m   1419\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1618\u001b[0m, in \u001b[0;36mBaseSGDRegressor._fit_regressor\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     average_coef \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# Not used\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m     average_intercept \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m]  \u001b[39m# Not used\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m coef, intercept, average_coef, average_intercept, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m _plain_sgd(\n\u001b[1;32m   1619\u001b[0m     coef,\n\u001b[1;32m   1620\u001b[0m     intercept[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m   1621\u001b[0m     average_coef,\n\u001b[1;32m   1622\u001b[0m     average_intercept[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m   1623\u001b[0m     loss_function,\n\u001b[1;32m   1624\u001b[0m     penalty_type,\n\u001b[1;32m   1625\u001b[0m     alpha,\n\u001b[1;32m   1626\u001b[0m     C,\n\u001b[1;32m   1627\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1628\u001b[0m     dataset,\n\u001b[1;32m   1629\u001b[0m     validation_mask,\n\u001b[1;32m   1630\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mearly_stopping,\n\u001b[1;32m   1631\u001b[0m     validation_score_cb,\n\u001b[1;32m   1632\u001b[0m     \u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter_no_change),\n\u001b[1;32m   1633\u001b[0m     max_iter,\n\u001b[1;32m   1634\u001b[0m     tol,\n\u001b[1;32m   1635\u001b[0m     \u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept),\n\u001b[1;32m   1636\u001b[0m     \u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose),\n\u001b[1;32m   1637\u001b[0m     \u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshuffle),\n\u001b[1;32m   1638\u001b[0m     seed,\n\u001b[1;32m   1639\u001b[0m     \u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m   1640\u001b[0m     \u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m   1641\u001b[0m     learning_rate_type,\n\u001b[1;32m   1642\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meta0,\n\u001b[1;32m   1643\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpower_t,\n\u001b[1;32m   1644\u001b[0m     \u001b[39m0\u001b[39;49m,\n\u001b[1;32m   1645\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mt_,\n\u001b[1;32m   1646\u001b[0m     intercept_decay,\n\u001b[1;32m   1647\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maverage,\n\u001b[1;32m   1648\u001b[0m )\n\u001b[1;32m   1650\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m*\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1652\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maverage \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "score_lst = []\n",
    "# for i in [6508,36400]:\n",
    "for i in range(1000,10000):\n",
    "    for j in [1e-4,1e-5,1e-6]:\n",
    "        reg = make_pipeline(StandardScaler(),SGDRegressor(max_iter=10000, tol=1e-6,penalty='l1',random_state=i))\n",
    "        # pred = evaluate2(reg, train, test, train_y, real_return)\n",
    "        pred, score = evaluate3(reg, train, test, train_y, real_return)\n",
    "        print(score)\n",
    "        score_lst.append(score)\n",
    "print(max(score_lst), score_lst.index(max(score_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00083867],\n",
       "       [ 0.00175657],\n",
       "       [ 0.00125077],\n",
       "       ...,\n",
       "       [-0.00226737],\n",
       "       [-0.00159325],\n",
       "       [-0.00088492]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          return         0\n",
      "return  1.000000  0.231504\n",
      "0       0.231504  1.000000\n",
      "          0         0\n",
      "0  1.000000  0.032785\n",
      "0  0.032785  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_regression\n",
    "regr = RandomForestRegressor(max_depth=7, random_state=6508, max_features=2, min_samples_leaf=4, min_samples_split=8, n_estimators=300)\n",
    "pred = evaluate2(regr, train, test, train_y, real_return)\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "# param_grid = {\n",
    "#     'bootstrap': [True],\n",
    "#     'max_depth': [7, 8, 9, 10],\n",
    "#     'max_features': [2, 3],\n",
    "#     'min_samples_leaf': [3, 4, 5],\n",
    "#     'min_samples_split': [8, 10, 12],\n",
    "#     'n_estimators': [100, 200, 300, 1000]\n",
    "# }\n",
    "\n",
    "# # Create a based model\n",
    "# rf = RandomForestRegressor()\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "#                           cv = 3, n_jobs = -1, verbose = 2)\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(train, train_y)\n",
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00693541, -0.00595175, -0.00669454, ..., -0.04251722,\n",
       "       -0.03254871, -0.02641362])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_arr = np.array(pred_com.iloc[:,1])\n",
    "submit_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(submit_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "800b2c1448e2ea079d66e8039536a26ab9dab7a446f882031feb022006dbbbf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
