{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import lightgbm as lgb\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# from lightgbm import LGBMRegressor\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import tqdm\n",
    "\n",
    "n_fold = 10\n",
    "group_gap = 31\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../qids_package/first_round_test_market_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m df_train_return \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(TRAIN_RETURN_PATH)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m df_train_fundamental \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(TRAIN_FUNADMENTAL_PATH)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m df_test_market \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(TEST_MARKET_PATH)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m df_test_fundamental \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(TEST_FUNADMENTAL_PATH)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#merge train dataset and test dataset\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     f,\n\u001b[1;32m   1219\u001b[0m     mode,\n\u001b[1;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1226\u001b[0m )\n\u001b[1;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../qids_package/first_round_test_market_data.csv'"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = \"../../data/\"\n",
    "TRAIN_MARKET_PATH = f'{ROOT_PATH}first_round_train_market_data.csv'\n",
    "# TRAIN_MARKET_PATH = f'{ROOT_PATH}train.csv'\n",
    "TRAIN_FUNADMENTAL_PATH = f'{ROOT_PATH}first_round_train_fundamental_data.csv'\n",
    "TRAIN_RETURN_PATH = f'{ROOT_PATH}first_round_train_return_data.csv'\n",
    "\n",
    "TEST_ROOT_PATH = \"../qids_package/\"\n",
    "TEST_MARKET_PATH = f'{TEST_ROOT_PATH}first_round_test_market_data.csv'\n",
    "# TEST_MARKET_PATH = f'{ROOT_PATH}test.csv'\n",
    "TEST_FUNADMENTAL_PATH = f'{TEST_ROOT_PATH}first_round_test_fundamental_data.csv'\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 6)\n",
    "pd.set_option('display.max_columns', 350)\n",
    "\n",
    "#read data\n",
    "df_train_market = pd.read_csv(TRAIN_MARKET_PATH)\n",
    "df_train_return = pd.read_csv(TRAIN_RETURN_PATH)\n",
    "df_train_fundamental = pd.read_csv(TRAIN_FUNADMENTAL_PATH)\n",
    "\n",
    "df_test_market = pd.read_csv(TEST_MARKET_PATH)\n",
    "df_test_fundamental = pd.read_csv(TEST_FUNADMENTAL_PATH)\n",
    "\n",
    "#merge train dataset and test dataset\n",
    "def split_time(x):\n",
    "    df1 = x['date_time'].str.split('d', expand=True)\n",
    "    df1.columns=['code','s']\n",
    "    code = df1['code']\n",
    "    df1 = df1['s'].str.split('p', expand=True)\n",
    "    df1.columns=['day','time_step']\n",
    "    df2 = x['date_time'].str.rsplit('p', expand=True)\n",
    "    df2.columns=['day_s','s']\n",
    "    df1['day_s'] = df2['day_s']\n",
    "    df1['code'] = code\n",
    "    x = pd.concat([x,df1],axis=1)\n",
    "    return x\n",
    "\n",
    "df_train_market = split_time(df_train_market)\n",
    "df = pd.merge(df_train_fundamental,df_train_market, left_on='date_time',right_on='day_s')  \n",
    "df = pd.merge(df,df_train_return, left_on='day_s',right_on='date_time')  \n",
    "\n",
    "df_test_market = split_time(df_test_market)\n",
    "test = pd.merge(df_test_fundamental,df_test_market, left_on='date_time',right_on='day_s')  \n",
    "\n",
    "#drop duplicates\n",
    "df = df.drop_duplicates(subset='day_s', keep='last').reset_index(drop=True)\n",
    "test = test.drop_duplicates(subset='day_s', keep='last').reset_index(drop=True)\n",
    "\n",
    "def growth(data, features, group):\n",
    "    \n",
    "    \"\"\"\n",
    "    create growth rate column based on selected features\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for feature in features:\n",
    "        data[f'{feature}_growth'] = grouped[feature].pct_change()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def lag_feature_with_group(data, features, n, group):\n",
    "\n",
    "    \"\"\"\n",
    "    create a lagged column in data from feature with n lagging periods\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for feature in features:\n",
    "            data[f'{feature}_{i}'] = grouped[feature].shift(i)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def sma(data, features, n, group):\n",
    "    \n",
    "    \"\"\"\n",
    "    create sma(n) column in data from feature\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for i in n:\n",
    "        for feature in features:\n",
    "            data[f'{feature}_sma{i}'] = grouped.rolling(i)[feature].mean().reset_index(drop=True)\n",
    "        \n",
    "    return data\n",
    "\n",
    "features = ['pe_ttm', 'pe', 'pb', 'ps', 'pcf']\n",
    "sma_periods = [10,25,50]\n",
    "df_lag = lag_feature_with_group(df, features, 2, 'code')\n",
    "df_sma = sma(df_lag, features, sma_periods, 'code')\n",
    "df_growth = growth(df_sma, features, 'code')\n",
    "# fig, ax = plt.subplots(figsize=(7,15))\n",
    "# sns.heatmap(df_lag.corr(numeric_only=True)[['return']].sort_values(by='return', ascending=False),annot=True);\n",
    "\n",
    "test = lag_feature_with_group(test, features, 2, 'code')\n",
    "test = sma(test, features, sma_periods, 'code')\n",
    "test = growth(test, features, 'code')\n",
    "\n",
    "# df = df.dropna()\n",
    "# test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time(x):\n",
    "    df1 = x['date_time'].str.split('d', expand=True)\n",
    "    df1.columns=['code','s']\n",
    "    code = df1['code']\n",
    "    df1 = df1['s'].str.split('p', expand=True)\n",
    "    df1.columns=['day','time_step']\n",
    "    df2 = x['date_time'].str.rsplit('p', expand=True)\n",
    "    df2.columns=['day_s','s']\n",
    "    df1['day_s'] = df2['day_s']\n",
    "    df1['code'] = code\n",
    "    x = pd.concat([x,df1],axis=1)\n",
    "    return x\n",
    "\n",
    "def growth(data, features, group):\n",
    "    \n",
    "    \"\"\"\n",
    "    create growth rate column based on selected features\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for feature in features:\n",
    "        data[f'{feature}_growth'] = grouped[feature].pct_change()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def lag_feature_with_group(data, features, n, group):\n",
    "\n",
    "    \"\"\"\n",
    "    create a lagged column in data from feature with n lagging periods\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for feature in features:\n",
    "            data[f'{feature}_{i}'] = grouped[feature].shift(i)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def sma(data, features, n, group):\n",
    "    \n",
    "    \"\"\"\n",
    "    create sma(n) column in data from feature\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for i in n:\n",
    "        for feature in features:\n",
    "            data[f'{feature}_sma{i}'] = grouped.rolling(i)[feature].mean().reset_index(drop=True)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def preprocess(fun, mar, ret=None):\n",
    "    fun[\"stock_id\"] = fun[\"date_time\"].apply(lambda x: x.split(\"d\")[0][1:]).astype(\"int\")\n",
    "    fun[\"day\"] = fun[\"date_time\"].apply(lambda x: x.split(\"d\")[1][:]).astype(\"int\")\n",
    "    # fun[\"log_pb\"] = calc_log(fun[\"pb\"])\n",
    "    # fun[\"log_ps\"] = calc_log(fun[\"ps\"])\n",
    "    fun = fun.sort_values(by=[\"stock_id\", \"day\"])\n",
    "    na_fun = fun.loc[fun[\"day\"].isin([999, 1000])]\n",
    "    fun = fun.drop(na_fun.index, axis=0).reset_index(drop=True)\n",
    "    na_fun = na_fun.reset_index(drop=True)\n",
    "\n",
    "    mar[\"stock_id\"] = mar[\"date_time\"].apply(lambda x: x.split(\"d\")[0][1:]).astype(\"int\")\n",
    "    mar[\"day\"] = mar[\"date_time\"].apply(lambda x: x.split(\"d\")[1].split(\"p\")[0]).astype(\"int\")\n",
    "    mar[\"time\"] = mar[\"date_time\"].apply(lambda x: x.split(\"p\")[1]).astype(\"int\")\n",
    "    mar = mar.sort_values(by=[\"stock_id\", \"day\", \"time\"]).reset_index(drop=True)\n",
    "    na_mar = mar.loc[mar[\"day\"].isin([999, 1000])]\n",
    "    mar = mar.drop(na_mar.index, axis=0).reset_index(drop=True)\n",
    "    na_mar = na_mar.reset_index(drop=True)\n",
    "\n",
    "    combined = copy.deepcopy(fun)\n",
    "    if ret is not None:\n",
    "        ret[\"stock_id\"] = ret[\"date_time\"].apply(lambda x: x.split(\"d\")[0][1:]).astype(\"int\")\n",
    "        ret[\"day\"] = ret[\"date_time\"].apply(lambda x: x.split(\"d\")[1][:]).astype(\"int\")\n",
    "        # ret[\"log_pb\"] = calc_log(ret[\"pb\"])\n",
    "        # ret[\"log_ps\"] = calc_log(ret[\"ps\"])\n",
    "        ret = ret.sort_values(by=[\"stock_id\", \"day\"]).reset_index(drop=True)\n",
    "        combined[\"return\"] = ret[\"return\"]\n",
    "        day_num = train_day_num\n",
    "    else:\n",
    "        day_num = test_day_num\n",
    "\n",
    "    mar_summary = []\n",
    "    start = 0\n",
    "    for stock in range(stock_num):\n",
    "        end = start + day_num * timeslot_num\n",
    "        stock_info = mar.iloc[start:end, :]\n",
    "        day_start = 0\n",
    "        for day in range(day_num):\n",
    "            day_end = day_start + timeslot_num\n",
    "            stock_info_per_day = stock_info.iloc[day_start:day_end, :]\n",
    "            mar_summary.append([\n",
    "                calc_mean(stock_info_per_day[\"open\"]),\n",
    "                calc_mean(stock_info_per_day[\"close\"]),\n",
    "                calc_mean(stock_info_per_day[\"high\"]),\n",
    "                calc_mean(stock_info_per_day[\"low\"]),\n",
    "                calc_mean(stock_info_per_day[\"volume\"]),\n",
    "                calc_mean(stock_info_per_day[\"money\"]),\n",
    "                calc_max(stock_info_per_day[\"high\"]),\n",
    "                calc_max(stock_info_per_day[\"volume\"]),\n",
    "                calc_max(stock_info_per_day[\"money\"]),\n",
    "                calc_min(stock_info_per_day[\"low\"]),\n",
    "                calc_min(stock_info_per_day[\"volume\"]),\n",
    "                calc_min(stock_info_per_day[\"money\"]),\n",
    "                calc_std(stock_info_per_day[\"volume\"]),\n",
    "                calc_std(stock_info_per_day[\"money\"]),\n",
    "                calc_var(stock_info_per_day[\"volume\"]),\n",
    "                calc_var(stock_info_per_day[\"money\"]),\n",
    "                calc_max(calc_div(calc_diff(stock_info_per_day[\"close\"], stock_info_per_day[\"open\"]), stock_info_per_day[\"open\"])),\n",
    "                calc_max(calc_div(calc_diff(stock_info_per_day[\"high\"], stock_info_per_day[\"low\"]), stock_info_per_day[\"open\"])),\n",
    "            ])\n",
    "            day_start = day_end\n",
    "        start = end\n",
    "    cols = [\n",
    "        \"open_mean\",\n",
    "        \"close_mean\",\n",
    "        \"high_mean\",\n",
    "        \"low_mean\",\n",
    "        \"volume_mean\",\n",
    "        \"money_mean\",\n",
    "        \"high_max\",\n",
    "        \"volume_max\",\n",
    "        \"money_max\",\n",
    "        \"low_min\",\n",
    "        \"volume_min\",\n",
    "        \"money_min\",\n",
    "        \"volume_std\",\n",
    "        \"money_std\",\n",
    "        \"volume_var\",\n",
    "        \"money_var\",\n",
    "        \"price_diff\",\n",
    "        \"price_diff_max\",\n",
    "    ]\n",
    "    mar_summary = pd.DataFrame(mar_summary, columns=cols)\n",
    "    combined = pd.concat([combined, mar_summary], axis=1)\n",
    "\n",
    "    return [combined, fun, mar, na_fun, na_mar, ret] if ret is not None else [combined, fun, mar, na_fun, na_mar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "fundamental_df = pd.read_csv(\"/Users/joellau/Desktop/Kaggle/QIDS/data/fun_test.csv\")\n",
    "market_df = pd.read_csv(\"/Users/joellau/Desktop/Kaggle/QIDS/data/mar_test.csv\")\n",
    "features = ['pe_ttm', 'pe', 'pb', 'ps', 'pcf']\n",
    "sma_periods = [10,25,50]\n",
    "\n",
    "features = ['pe_ttm', 'pe', 'pb', 'ps', 'pcf']\n",
    "sma_periods = [10,25,50]\n",
    "\n",
    "market_df = split_time(market_df)\n",
    "test = pd.merge(fundamental_df,market_df, left_on='date_time',right_on='day_s')\n",
    "test = test.drop_duplicates(subset='day_s', keep='last').reset_index(drop=True)\n",
    "test = lag_feature_with_group(test, features, 2, 'code')\n",
    "test = sma(test, features, sma_periods, 'code')\n",
    "test = growth(test, features, 'code')\n",
    "\n",
    "test = test.rename(columns={\"date_time_x\": \"date_time\"}).drop(columns=[\"date_time_y\", \"day_s\", \"code\"]).fillna(0)\n",
    "test_fun, test_mar = test, market_df\n",
    "\n",
    "# print(\"fundamental data:\", test_fun)\n",
    "# print(\"market data:\", test_mar)\n",
    "test_combined, test_fun, test_mar, test_na_fun, test_na_mar = preprocess(test_fun, test_mar)\n",
    "test = test_combined.drop(columns=['pcf_sma10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>date_time</th>\n",
       "      <th>turnoverRatio</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>pe_ttm</th>\n",
       "      <th>pe</th>\n",
       "      <th>pb</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "      <th>day</th>\n",
       "      <th>time_step</th>\n",
       "      <th>pe_ttm_1</th>\n",
       "      <th>pe_1</th>\n",
       "      <th>pb_1</th>\n",
       "      <th>ps_1</th>\n",
       "      <th>pcf_1</th>\n",
       "      <th>pe_ttm_2</th>\n",
       "      <th>pe_2</th>\n",
       "      <th>pb_2</th>\n",
       "      <th>ps_2</th>\n",
       "      <th>pcf_2</th>\n",
       "      <th>pe_ttm_sma10</th>\n",
       "      <th>pe_sma10</th>\n",
       "      <th>pb_sma10</th>\n",
       "      <th>ps_sma10</th>\n",
       "      <th>pe_ttm_sma25</th>\n",
       "      <th>pe_sma25</th>\n",
       "      <th>pb_sma25</th>\n",
       "      <th>ps_sma25</th>\n",
       "      <th>pcf_sma25</th>\n",
       "      <th>pe_ttm_sma50</th>\n",
       "      <th>pe_sma50</th>\n",
       "      <th>pb_sma50</th>\n",
       "      <th>ps_sma50</th>\n",
       "      <th>pcf_sma50</th>\n",
       "      <th>pe_ttm_growth</th>\n",
       "      <th>pe_growth</th>\n",
       "      <th>pb_growth</th>\n",
       "      <th>ps_growth</th>\n",
       "      <th>pcf_growth</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>open_mean</th>\n",
       "      <th>close_mean</th>\n",
       "      <th>high_mean</th>\n",
       "      <th>low_mean</th>\n",
       "      <th>volume_mean</th>\n",
       "      <th>money_mean</th>\n",
       "      <th>high_max</th>\n",
       "      <th>volume_max</th>\n",
       "      <th>money_max</th>\n",
       "      <th>low_min</th>\n",
       "      <th>volume_min</th>\n",
       "      <th>money_min</th>\n",
       "      <th>volume_std</th>\n",
       "      <th>money_std</th>\n",
       "      <th>volume_var</th>\n",
       "      <th>money_var</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>price_diff_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>s0d1001</td>\n",
       "      <td>1.1718</td>\n",
       "      <td>9290.0</td>\n",
       "      <td>63.6900</td>\n",
       "      <td>63.6900</td>\n",
       "      <td>1.6398</td>\n",
       "      <td>1.5477</td>\n",
       "      <td>-40.9539</td>\n",
       "      <td>2646.0</td>\n",
       "      <td>12.3929</td>\n",
       "      <td>12.3929</td>\n",
       "      <td>12.3929</td>\n",
       "      <td>12.3929</td>\n",
       "      <td>193641.0</td>\n",
       "      <td>2.398687e+06</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.290448</td>\n",
       "      <td>12.296764</td>\n",
       "      <td>12.317646</td>\n",
       "      <td>12.267632</td>\n",
       "      <td>240548.82</td>\n",
       "      <td>2.953956e+06</td>\n",
       "      <td>12.4050</td>\n",
       "      <td>946319.0</td>\n",
       "      <td>1.153619e+07</td>\n",
       "      <td>12.0773</td>\n",
       "      <td>30339.0</td>\n",
       "      <td>371325.6960</td>\n",
       "      <td>170960.906207</td>\n",
       "      <td>2.090812e+06</td>\n",
       "      <td>2.922763e+10</td>\n",
       "      <td>4.371496e+12</td>\n",
       "      <td>0.011992</td>\n",
       "      <td>0.017983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>s1d1001</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>9539.0</td>\n",
       "      <td>33.1536</td>\n",
       "      <td>33.1536</td>\n",
       "      <td>5.2277</td>\n",
       "      <td>3.3677</td>\n",
       "      <td>124.7176</td>\n",
       "      <td>2647.0</td>\n",
       "      <td>30.2479</td>\n",
       "      <td>30.2964</td>\n",
       "      <td>30.2964</td>\n",
       "      <td>30.2479</td>\n",
       "      <td>44257.0</td>\n",
       "      <td>1.340836e+06</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.977220</td>\n",
       "      <td>29.987896</td>\n",
       "      <td>30.078692</td>\n",
       "      <td>29.907798</td>\n",
       "      <td>76884.32</td>\n",
       "      <td>2.307872e+06</td>\n",
       "      <td>30.5149</td>\n",
       "      <td>190790.0</td>\n",
       "      <td>5.786716e+06</td>\n",
       "      <td>29.6167</td>\n",
       "      <td>11912.0</td>\n",
       "      <td>356279.4312</td>\n",
       "      <td>42062.480406</td>\n",
       "      <td>1.267908e+06</td>\n",
       "      <td>1.769252e+09</td>\n",
       "      <td>1.607590e+12</td>\n",
       "      <td>0.014238</td>\n",
       "      <td>0.017618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>s2d1001</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>9765.0</td>\n",
       "      <td>36.6197</td>\n",
       "      <td>36.6197</td>\n",
       "      <td>6.0413</td>\n",
       "      <td>4.4686</td>\n",
       "      <td>33.3814</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>23.8148</td>\n",
       "      <td>23.8148</td>\n",
       "      <td>23.8148</td>\n",
       "      <td>23.8148</td>\n",
       "      <td>33383.0</td>\n",
       "      <td>7.948739e+05</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.229222</td>\n",
       "      <td>23.240634</td>\n",
       "      <td>23.284810</td>\n",
       "      <td>23.174366</td>\n",
       "      <td>146867.32</td>\n",
       "      <td>3.430978e+06</td>\n",
       "      <td>23.9361</td>\n",
       "      <td>604978.0</td>\n",
       "      <td>1.442095e+07</td>\n",
       "      <td>22.8559</td>\n",
       "      <td>27263.0</td>\n",
       "      <td>630107.8560</td>\n",
       "      <td>128461.116273</td>\n",
       "      <td>3.041646e+06</td>\n",
       "      <td>1.650226e+10</td>\n",
       "      <td>9.251608e+12</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.013578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37797</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37798</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37799</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37800 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0_x date_time  turnoverRatio  transactionAmount   pe_ttm  \\\n",
       "0               0.0   s0d1001         1.1718             9290.0  63.6900   \n",
       "1               1.0   s1d1001         0.5027             9539.0  33.1536   \n",
       "2               2.0   s2d1001         0.5060             9765.0  36.6197   \n",
       "...             ...       ...            ...                ...      ...   \n",
       "37797           NaN       NaN            NaN                NaN      NaN   \n",
       "37798           NaN       NaN            NaN                NaN      NaN   \n",
       "37799           NaN       NaN            NaN                NaN      NaN   \n",
       "\n",
       "            pe      pb      ps       pcf  Unnamed: 0_y     open    close  \\\n",
       "0      63.6900  1.6398  1.5477  -40.9539        2646.0  12.3929  12.3929   \n",
       "1      33.1536  5.2277  3.3677  124.7176        2647.0  30.2479  30.2964   \n",
       "2      36.6197  6.0413  4.4686   33.3814        2648.0  23.8148  23.8148   \n",
       "...        ...     ...     ...       ...           ...      ...      ...   \n",
       "37797      NaN     NaN     NaN       NaN           NaN      NaN      NaN   \n",
       "37798      NaN     NaN     NaN       NaN           NaN      NaN      NaN   \n",
       "37799      NaN     NaN     NaN       NaN           NaN      NaN      NaN   \n",
       "\n",
       "          high      low    volume         money     day time_step  pe_ttm_1  \\\n",
       "0      12.3929  12.3929  193641.0  2.398687e+06  1001.0        50       0.0   \n",
       "1      30.2964  30.2479   44257.0  1.340836e+06  1001.0        50       0.0   \n",
       "2      23.8148  23.8148   33383.0  7.948739e+05  1001.0        50       0.0   \n",
       "...        ...      ...       ...           ...     ...       ...       ...   \n",
       "37797      NaN      NaN       NaN           NaN     NaN       NaN       NaN   \n",
       "37798      NaN      NaN       NaN           NaN     NaN       NaN       NaN   \n",
       "37799      NaN      NaN       NaN           NaN     NaN       NaN       NaN   \n",
       "\n",
       "       pe_1  pb_1  ps_1  pcf_1  pe_ttm_2  pe_2  pb_2  ps_2  pcf_2  \\\n",
       "0       0.0   0.0   0.0    0.0       0.0   0.0   0.0   0.0    0.0   \n",
       "1       0.0   0.0   0.0    0.0       0.0   0.0   0.0   0.0    0.0   \n",
       "2       0.0   0.0   0.0    0.0       0.0   0.0   0.0   0.0    0.0   \n",
       "...     ...   ...   ...    ...       ...   ...   ...   ...    ...   \n",
       "37797   NaN   NaN   NaN    NaN       NaN   NaN   NaN   NaN    NaN   \n",
       "37798   NaN   NaN   NaN    NaN       NaN   NaN   NaN   NaN    NaN   \n",
       "37799   NaN   NaN   NaN    NaN       NaN   NaN   NaN   NaN    NaN   \n",
       "\n",
       "       pe_ttm_sma10  pe_sma10  pb_sma10  ps_sma10  pe_ttm_sma25  pe_sma25  \\\n",
       "0               0.0       0.0       0.0       0.0           0.0       0.0   \n",
       "1               0.0       0.0       0.0       0.0           0.0       0.0   \n",
       "2               0.0       0.0       0.0       0.0           0.0       0.0   \n",
       "...             ...       ...       ...       ...           ...       ...   \n",
       "37797           NaN       NaN       NaN       NaN           NaN       NaN   \n",
       "37798           NaN       NaN       NaN       NaN           NaN       NaN   \n",
       "37799           NaN       NaN       NaN       NaN           NaN       NaN   \n",
       "\n",
       "       pb_sma25  ps_sma25  pcf_sma25  pe_ttm_sma50  pe_sma50  pb_sma50  \\\n",
       "0           0.0       0.0        0.0           0.0       0.0       0.0   \n",
       "1           0.0       0.0        0.0           0.0       0.0       0.0   \n",
       "2           0.0       0.0        0.0           0.0       0.0       0.0   \n",
       "...         ...       ...        ...           ...       ...       ...   \n",
       "37797       NaN       NaN        NaN           NaN       NaN       NaN   \n",
       "37798       NaN       NaN        NaN           NaN       NaN       NaN   \n",
       "37799       NaN       NaN        NaN           NaN       NaN       NaN   \n",
       "\n",
       "       ps_sma50  pcf_sma50  pe_ttm_growth  pe_growth  pb_growth  ps_growth  \\\n",
       "0           0.0        0.0            0.0        0.0        0.0        0.0   \n",
       "1           0.0        0.0            0.0        0.0        0.0        0.0   \n",
       "2           0.0        0.0            0.0        0.0        0.0        0.0   \n",
       "...         ...        ...            ...        ...        ...        ...   \n",
       "37797       NaN        NaN            NaN        NaN        NaN        NaN   \n",
       "37798       NaN        NaN            NaN        NaN        NaN        NaN   \n",
       "37799       NaN        NaN            NaN        NaN        NaN        NaN   \n",
       "\n",
       "       pcf_growth  stock_id  open_mean  close_mean  high_mean   low_mean  \\\n",
       "0             0.0       0.0  12.290448   12.296764  12.317646  12.267632   \n",
       "1             0.0       1.0  29.977220   29.987896  30.078692  29.907798   \n",
       "2             0.0       2.0  23.229222   23.240634  23.284810  23.174366   \n",
       "...           ...       ...        ...         ...        ...        ...   \n",
       "37797         NaN       NaN        NaN         NaN        NaN        NaN   \n",
       "37798         NaN       NaN        NaN         NaN        NaN        NaN   \n",
       "37799         NaN       NaN        NaN         NaN        NaN        NaN   \n",
       "\n",
       "       volume_mean    money_mean  high_max  volume_max     money_max  low_min  \\\n",
       "0        240548.82  2.953956e+06   12.4050    946319.0  1.153619e+07  12.0773   \n",
       "1         76884.32  2.307872e+06   30.5149    190790.0  5.786716e+06  29.6167   \n",
       "2        146867.32  3.430978e+06   23.9361    604978.0  1.442095e+07  22.8559   \n",
       "...            ...           ...       ...         ...           ...      ...   \n",
       "37797          NaN           NaN       NaN         NaN           NaN      NaN   \n",
       "37798          NaN           NaN       NaN         NaN           NaN      NaN   \n",
       "37799          NaN           NaN       NaN         NaN           NaN      NaN   \n",
       "\n",
       "       volume_min    money_min     volume_std     money_std    volume_var  \\\n",
       "0         30339.0  371325.6960  170960.906207  2.090812e+06  2.922763e+10   \n",
       "1         11912.0  356279.4312   42062.480406  1.267908e+06  1.769252e+09   \n",
       "2         27263.0  630107.8560  128461.116273  3.041646e+06  1.650226e+10   \n",
       "...           ...          ...            ...           ...           ...   \n",
       "37797         NaN          NaN            NaN           NaN           NaN   \n",
       "37798         NaN          NaN            NaN           NaN           NaN   \n",
       "37799         NaN          NaN            NaN           NaN           NaN   \n",
       "\n",
       "          money_var  price_diff  price_diff_max  \n",
       "0      4.371496e+12    0.011992        0.017983  \n",
       "1      1.607590e+12    0.014238        0.017618  \n",
       "2      9.251608e+12    0.009733        0.013578  \n",
       "...             ...         ...             ...  \n",
       "37797           NaN         NaN             NaN  \n",
       "37798           NaN         NaN             NaN  \n",
       "37799           NaN         NaN             NaN  \n",
       "\n",
       "[37800 rows x 66 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 115>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb#W2sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m     combined \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([combined, mar_summary], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb#W2sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [combined, fun, mar, na_fun, na_mar, ret] \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m [combined, fun, mar, na_fun, na_mar]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb#W2sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m train \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mdate_time_x\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdate_time_y\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mday_s\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mfillna(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb#W2sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m test \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdate_time_x\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mdate_time\u001b[39m\u001b[39m\"\u001b[39m})\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mdate_time_y\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mday_s\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mfillna(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joellau/Desktop/Kaggle/QIDS/py/preprocess_github.ipynb#W2sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m train_fun, train_mar, train_ret \u001b[39m=\u001b[39m train, df_train_market, df_train_return\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 257248\n",
    "stock_num = 54\n",
    "train_day_num_total = 1000\n",
    "train_day_num = 1000 - 2\n",
    "test_day_num = 700\n",
    "timeslot_num = 50\n",
    "\n",
    "calc_log = lambda df: np.log(np.where(df > 1e-8, df, 1e-8))\n",
    "calc_mean = lambda df: df.mean(axis=0)\n",
    "calc_max = lambda df: df.max(axis=0)\n",
    "calc_min = lambda df: df.min(axis=0)\n",
    "calc_std = lambda df: df.std()\n",
    "calc_var = lambda df: df.var()\n",
    "calc_add = lambda df1, df2: df1 + df2\n",
    "calc_diff = lambda df1, df2: df1 - df2\n",
    "calc_prod = lambda df1, df2: df1 * df2\n",
    "calc_div = lambda df1, df2: df1 / df2\n",
    "\n",
    "def preprocess(fun, mar, ret=None):\n",
    "    fun[\"stock_id\"] = fun[\"date_time\"].apply(lambda x: x.split(\"d\")[0][1:]).astype(\"int\")\n",
    "    fun[\"day\"] = fun[\"date_time\"].apply(lambda x: x.split(\"d\")[1][:]).astype(\"int\")\n",
    "    # fun[\"log_pb\"] = calc_log(fun[\"pb\"])\n",
    "    # fun[\"log_ps\"] = calc_log(fun[\"ps\"])\n",
    "    fun = fun.sort_values(by=[\"stock_id\", \"day\"])\n",
    "    na_fun = fun.loc[fun[\"day\"].isin([999, 1000])]\n",
    "    fun = fun.drop(na_fun.index, axis=0).reset_index(drop=True)\n",
    "    na_fun = na_fun.reset_index(drop=True)\n",
    "\n",
    "    mar[\"stock_id\"] = mar[\"date_time\"].apply(lambda x: x.split(\"d\")[0][1:]).astype(\"int\")\n",
    "    mar[\"day\"] = mar[\"date_time\"].apply(lambda x: x.split(\"d\")[1].split(\"p\")[0]).astype(\"int\")\n",
    "    mar[\"time\"] = mar[\"date_time\"].apply(lambda x: x.split(\"p\")[1]).astype(\"int\")\n",
    "    mar = mar.sort_values(by=[\"stock_id\", \"day\", \"time\"]).reset_index(drop=True)\n",
    "    na_mar = mar.loc[mar[\"day\"].isin([999, 1000])]\n",
    "    mar = mar.drop(na_mar.index, axis=0).reset_index(drop=True)\n",
    "    na_mar = na_mar.reset_index(drop=True)\n",
    "\n",
    "    combined = copy.deepcopy(fun)\n",
    "    if ret is not None:\n",
    "        ret[\"stock_id\"] = ret[\"date_time\"].apply(lambda x: x.split(\"d\")[0][1:]).astype(\"int\")\n",
    "        ret[\"day\"] = ret[\"date_time\"].apply(lambda x: x.split(\"d\")[1][:]).astype(\"int\")\n",
    "        # ret[\"log_pb\"] = calc_log(ret[\"pb\"])\n",
    "        # ret[\"log_ps\"] = calc_log(ret[\"ps\"])\n",
    "        ret = ret.sort_values(by=[\"stock_id\", \"day\"]).reset_index(drop=True)\n",
    "        combined[\"return\"] = ret[\"return\"]\n",
    "        day_num = train_day_num\n",
    "    else:\n",
    "        day_num = test_day_num\n",
    "\n",
    "    mar_summary = []\n",
    "    start = 0\n",
    "    for stock in range(stock_num):\n",
    "        end = start + day_num * timeslot_num\n",
    "        stock_info = mar.iloc[start:end, :]\n",
    "        day_start = 0\n",
    "        for day in range(day_num):\n",
    "            day_end = day_start + timeslot_num\n",
    "            stock_info_per_day = stock_info.iloc[day_start:day_end, :]\n",
    "            mar_summary.append([\n",
    "                calc_mean(stock_info_per_day[\"open\"]),\n",
    "                calc_mean(stock_info_per_day[\"close\"]),\n",
    "                calc_mean(stock_info_per_day[\"high\"]),\n",
    "                calc_mean(stock_info_per_day[\"low\"]),\n",
    "                calc_mean(stock_info_per_day[\"volume\"]),\n",
    "                calc_mean(stock_info_per_day[\"money\"]),\n",
    "                calc_max(stock_info_per_day[\"high\"]),\n",
    "                calc_max(stock_info_per_day[\"volume\"]),\n",
    "                calc_max(stock_info_per_day[\"money\"]),\n",
    "                calc_min(stock_info_per_day[\"low\"]),\n",
    "                calc_min(stock_info_per_day[\"volume\"]),\n",
    "                calc_min(stock_info_per_day[\"money\"]),\n",
    "                calc_std(stock_info_per_day[\"volume\"]),\n",
    "                calc_std(stock_info_per_day[\"money\"]),\n",
    "                calc_var(stock_info_per_day[\"volume\"]),\n",
    "                calc_var(stock_info_per_day[\"money\"]),\n",
    "                calc_max(calc_div(calc_diff(stock_info_per_day[\"close\"], stock_info_per_day[\"open\"]), stock_info_per_day[\"open\"])),\n",
    "                calc_max(calc_div(calc_diff(stock_info_per_day[\"high\"], stock_info_per_day[\"low\"]), stock_info_per_day[\"open\"])),\n",
    "            ])\n",
    "            day_start = day_end\n",
    "        start = end\n",
    "    cols = [\n",
    "        \"open_mean\",\n",
    "        \"close_mean\",\n",
    "        \"high_mean\",\n",
    "        \"low_mean\",\n",
    "        \"volume_mean\",\n",
    "        \"money_mean\",\n",
    "        \"high_max\",\n",
    "        \"volume_max\",\n",
    "        \"money_max\",\n",
    "        \"low_min\",\n",
    "        \"volume_min\",\n",
    "        \"money_min\",\n",
    "        \"volume_std\",\n",
    "        \"money_std\",\n",
    "        \"volume_var\",\n",
    "        \"money_var\",\n",
    "        \"price_diff\",\n",
    "        \"price_diff_max\",\n",
    "    ]\n",
    "    mar_summary = pd.DataFrame(mar_summary, columns=cols)\n",
    "    combined = pd.concat([combined, mar_summary], axis=1)\n",
    "\n",
    "    return [combined, fun, mar, na_fun, na_mar, ret] if ret is not None else [combined, fun, mar, na_fun, na_mar]\n",
    "\n",
    "train = df.drop(columns=[\"date_time_x\", \"date_time_y\", \"day_s\", \"code\"]).fillna(0)\n",
    "test = test.rename(columns={\"date_time_x\": \"date_time\"}).drop(columns=[\"date_time_y\", \"day_s\", \"code\"]).fillna(0)\n",
    "\n",
    "train_fun, train_mar, train_ret = train, df_train_market, df_train_return\n",
    "test_fun, test_mar = test, df_test_market\n",
    "\n",
    "train_combined, train_fun, train_mar, train_na_fun, train_na_mar, train_ret = preprocess(train_fun, train_mar, train_ret)\n",
    "test_combined, test_fun, test_mar, test_na_fun, test_na_mar = preprocess(test_fun, test_mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(df):\n",
    "    df_cols = df.columns\n",
    "    if 'return' not in df_cols:\n",
    "        df_cols_prior = ['date_time', 'stock_id', 'day']\n",
    "    else:\n",
    "        df_cols_prior = ['date_time', 'stock_id', 'day', 'return']\n",
    "    for col in df_cols:\n",
    "        if col not in df_cols_prior:\n",
    "            df_cols_prior.append(col)\n",
    "    if 'return' in df_cols_prior:\n",
    "        df_cols_prior.remove('return')\n",
    "        df_cols_prior.append('return')\n",
    "    return df[df_cols_prior]\n",
    "\n",
    "train = reorder(train_combined)\n",
    "test = reorder(test_combined)\n",
    "\n",
    "train.to_csv(\"../../data/train_github.csv\", index=False)\n",
    "test.to_csv(\"../../data/test_github.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
